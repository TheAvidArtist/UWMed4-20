{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## General Imports\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime as dt\n",
    "import os\n",
    "#Change working directory to directory working in\n",
    "os.chdir(r\"C:\\Users\\kaitl\\Desktop\\HospitalAerosolTesting\\Data\\UWMedApril20\")\n",
    "import glob\n",
    "from cleanUp import cleanUp\n",
    "from fillDf import fillDf\n",
    "from fixYearStamp import fixYearStamp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Passing the sensor data through the cleanUp function to get fix timestamps and delete null timestamps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_csv_files = glob.glob(\"./Data/*.txt\")\n",
    "# insert the desired start time\n",
    "cutOffTime = '4/20/2021 9:30'\n",
    "# insert the time rectifying offsets. default of for nothing {'':0}\n",
    "sensorConditions = {'S-15':7,'S-19':7}\n",
    "#This indicates which columns to keep. Here we're taking all of the dP info and the timestamps\n",
    "columns = [0,1,6,7,8,9,10,11]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['./Data\\\\S-01.txt',\n",
       " './Data\\\\S-02.txt',\n",
       " './Data\\\\S-03.txt',\n",
       " './Data\\\\S-04.txt',\n",
       " './Data\\\\S-05.txt',\n",
       " './Data\\\\S-06.txt',\n",
       " './Data\\\\S-07.txt',\n",
       " './Data\\\\S-08.txt',\n",
       " './Data\\\\S-10.txt',\n",
       " './Data\\\\S-12.txt',\n",
       " './Data\\\\S-13.txt',\n",
       " './Data\\\\S-14.txt',\n",
       " './Data\\\\S-15.txt',\n",
       " './Data\\\\S-16.txt',\n",
       " './Data\\\\S-18.txt',\n",
       " './Data\\\\S-19.txt']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_csv_files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Changed this to markdown so it won't run twice, had to fix the timestamps on S-12 filePath = all_csv_files[11] incorrectString = '21/3/22' date = '3/22/2021' charTimeStart = 11 charTimeEnd = 21 offset = 0 fixYearStamp(filePath,incorrectString,date,charTimeStart,charTimeEnd,offset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "S-01     2021-04-20 09:30:00      2021-04-20 13:45:59\n",
      "S-02     2021-04-20 09:30:00      2021-04-20 13:46:00\n",
      "S-03     2021-04-20 09:30:00      2021-04-20 13:45:19\n",
      "S-04     2021-04-20 09:30:09      2021-04-20 13:49:09\n",
      "S-05     2021-04-20 09:30:00      2021-04-20 13:43:50\n",
      "S-06     2021-04-20 09:30:00      2021-04-20 13:44:09\n",
      "S-07     2021-04-20 09:30:07      2021-04-20 13:45:27\n",
      "S-08     2021-04-20 09:30:09      2021-04-20 13:47:03\n",
      "S-10     2021-04-20 09:30:07      2021-04-20 13:44:23\n",
      "S-12     2021-04-20 09:30:14      2021-04-20 13:45:15\n",
      "S-13     2021-04-20 09:30:08      2021-04-20 13:44:38\n",
      "S-14     2021-04-20 09:30:07      2021-04-20 13:43:57\n",
      "S-15     2021-04-20 09:30:03      2021-04-20 13:48:44\n",
      "S-16     2021-04-20 09:31:17      2021-04-20 13:49:17\n",
      "S-18     2021-04-20 09:30:08      2021-04-20 13:48:39\n",
      "S-19     2021-04-20 09:30:02      2021-04-20 13:49:12\n"
     ]
    }
   ],
   "source": [
    "data = cleanUp(cutOffTime,sensorConditions,all_csv_files,columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exporting Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we can export the organized data frames as csv files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "directory = './proccessedData'\n",
    "for x in data:\n",
    "    temp=data[x]\n",
    "    if not os.path.exists(directory):\n",
    "        os.makedirs(directory)\n",
    "    location = os.path.join(directory,x+'.csv')\n",
    "    temp.to_csv(location,index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Checking Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we scan through the data for irregularities in data recording."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.59 % potential error in  S-01\n",
      "   9 43085990\n",
      "   1   4   4\n",
      "\n",
      "0.52 % potential error in  S-02\n",
      " 43085990\n",
      "   4   4\n",
      "\n",
      "0.65 % potential error in  S-03\n",
      "   9  20 43085990\n",
      "   1   1   4   4\n",
      "\n",
      "0.84 % potential error in  S-04\n",
      "   9 43085990  81  15   5  20\n",
      "   1   4   4   1   1   1   1\n",
      "\n",
      "1.39 % potential error in  S-05\n",
      "  73   9 43085990 611 810  17  81  20\n",
      "   1   2   4   4   1   1   1   1   4\n",
      "\n",
      "0.66 % potential error in  S-06\n",
      "   9 43085990  20\n",
      "   1   4   4   1\n",
      "\n",
      "19.95 % potential error in  S-07\n",
      "  20\n",
      " 255\n",
      "\n",
      "50.0 % potential error in  S-08\n",
      "  21  17  11 126  19  20\n",
      "   3   1   1   1   3 502\n",
      "\n",
      "50.0 % potential error in  S-10\n",
      "  17  44  19  26  20\n",
      "   1   1   1   1 504\n",
      "\n",
      "99.81 % potential error in  S-12\n",
      "  20  80 400  211820  60 660 260  61 160 620  19  40 820\n",
      " 494   1   1   5   1   3   1   1   1   1   1   5   4   1\n",
      "\n",
      "19.94 % potential error in  S-13\n",
      "  20\n",
      " 254\n",
      "\n",
      "50.76 % potential error in  S-14\n",
      "  20 100 420  30 460  40 340\n",
      " 461   1   1   1   1   3   1\n",
      "\n",
      "0.06 % potential error in  S-15\n",
      "  11\n",
      "   1\n",
      "\n",
      "0.0 % potential error in  S-16\n",
      "\n",
      "\n",
      "\n",
      "0.13 % potential error in  S-18\n",
      "  57  14\n",
      "   1   1\n",
      "\n",
      "0.0 % potential error in  S-19\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data = data\n",
    "fout = open('./dataInfo/time_Frequency_Error_Log.txt','wt')\n",
    "errors = {}\n",
    "errorCount = {}\n",
    "# Enter the expected interval here\n",
    "interval = 10\n",
    "for x in data:\n",
    "    # errors keeps track of length of each time interval error that occurs\n",
    "    errors[x] = set(())\n",
    "    # errorCount keeps track of how many times each time interval error occured\n",
    "    errorCount[x] = {}\n",
    "    # counter keeps track of the total time interval errors per sensor\n",
    "    counter = 0\n",
    "    #shows the total\n",
    "    temp = data[x]\n",
    "    for idx,i in enumerate(temp['Date_Time']):\n",
    "        try:\n",
    "            if not ((temp['Date_Time'][idx+1] - i) == pd.Timedelta(seconds=interval)):\n",
    "                timeErr = temp['Date_Time'][idx+1] - i\n",
    "                if str(timeErr.seconds) in errorCount[x]:\n",
    "                    errorCount[x][str(timeErr.seconds)] +=1\n",
    "                else:\n",
    "                    errorCount[x][str(timeErr.seconds)] = 1\n",
    "\n",
    "                errors[x].add(timeErr)\n",
    "\n",
    "\n",
    "                counter += 1\n",
    "        except:\n",
    "                        \n",
    "            continue\n",
    "\n",
    "    print(str(round(counter/len(temp)*100,2)),'% potential error in ', x)\n",
    "    fout.write('potential error in '+ x +'\\n' + str(round(counter/len(temp)*100,2))+'%'+'\\n')\n",
    "\n",
    "    # display the different types of errors\n",
    "    lst = [i.seconds for i in errors[x]]\n",
    "    frmt = \"{:>4}\"*len(lst)\n",
    "    print(frmt.format(*lst))\n",
    "    fout.write(\"Time Errors\" + frmt.format(*lst)+ '\\n')\n",
    "        # display the quantity of each type of error\n",
    "    lst = [errorCount[x][str(i.seconds)] for i in errors[x]]\n",
    "    frmt = \"{:>4}\"*len(lst)\n",
    "    print(frmt.format(*lst))\n",
    "    fout.write(\"# Observed \" + frmt.format(*lst)+ '\\n')\n",
    "\n",
    "    print()\n",
    "    fout.write('\\n')\n",
    "\n",
    "\n",
    "fout.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice there are quite a few repeating errors here in our data set. We can either choose to interpolate the data inbetween or pad it with 0s. For gaps <40s i will interpolate, but for gaps >40 i will 0 pad."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "S-01   ['% of values from interpolation : 0.0', '% of values from 0-padding : 8.073', '% of values not changed : 91.927']\n",
      "S-02   ['% of values from interpolation : 0.0', '% of values from 0-padding : 8.068', '% of values not changed : 91.932']\n",
      "S-03   ['% of values from interpolation : 0.0', '% of values from 0-padding : 8.094', '% of values not changed : 91.906']\n",
      "S-04   ['% of values from interpolation : 0.257', '% of values from 0-padding : 8.553', '% of values not changed : 91.19']\n",
      "S-05   ['% of values from interpolation : 0.656', '% of values from 0-padding : 18.57', '% of values not changed : 80.774']\n",
      "S-06   ['% of values from interpolation : 0.131', '% of values from 0-padding : 8.131', '% of values not changed : 91.738']\n",
      "S-07   ['% of values from interpolation : 33.268', '% of values from 0-padding : 0.0', '% of values not changed : 66.732']\n",
      "S-08   ['% of values from interpolation : 65.911', '% of values from 0-padding : 0.778', '% of values not changed : 33.312']\n",
      "S-10   ['% of values from interpolation : 66.339', '% of values from 0-padding : 0.327', '% of values not changed : 33.333']\n",
      "S-12   ['% of values from interpolation : 66.971', '% of values from 0-padding : 33.029', '% of values not changed : 0.0']\n",
      "S-13   ['% of values from interpolation : 33.246', '% of values from 0-padding : 0.0', '% of values not changed : 66.754']\n",
      "S-14   ['% of values from interpolation : 61.483', '% of values from 0-padding : 8.661', '% of values not changed : 29.856']\n",
      "S-15   ['% of values from interpolation : 0.0', '% of values from 0-padding : 0.0', '% of values not changed : 100.0']\n",
      "S-16   ['% of values from interpolation : 0.0', '% of values from 0-padding : 0.514', '% of values not changed : 99.486']\n",
      "S-18   ['% of values from interpolation : 0.0', '% of values from 0-padding : 0.387', '% of values not changed : 99.613']\n",
      "S-19   ['% of values from interpolation : 0.0', '% of values from 0-padding : 0.0', '% of values not changed : 100.0']\n"
     ]
    }
   ],
   "source": [
    "fout = open('./dataInfo/interpolation_Effect_Log.txt','wt')\n",
    "interpDF = {}\n",
    "\n",
    "for x in data:\n",
    "    df = data[x]\n",
    "    cutoff = 40\n",
    "    freq = '10S'\n",
    "    try:\n",
    "        interpDF[x],accuracy = fillDf(df,freq,'2021-04-20 9:30','2021-04-20 14:00',cutoff)\n",
    "        print(x,' ',accuracy)\n",
    "        fout.write(x+' '+ '\\n' + accuracy[0]+ '\\n'+ accuracy[1]+ '\\n'+ accuracy[2] +'\\n\\n')\n",
    "    except IndexError:\n",
    "        print(x,'NO DATA')\n",
    "        fout.write(x+'NO DATA'+'\\n')\n",
    "fout.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "export the newly interpolated data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "directory = './interpolatedData'\n",
    "for x in interpDF:\n",
    "    temp=interpDF[x]\n",
    "    if not os.path.exists(directory):\n",
    "        os.makedirs(directory)\n",
    "    location = os.path.join(directory,x+'.csv')\n",
    "    temp.to_csv(location,index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merge the DataFrames"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Also remove 'S-02' from the dictionary as it has no real data and find the least common index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1524\n"
     ]
    }
   ],
   "source": [
    "# interpDF.pop('S-02',None)\n",
    "# interpDF.pop('S-BU2',None)\n",
    "# interpDF.pop('S-BU1',None)\n",
    "#interpDF.pop('S19',None)\n",
    "#interpDF.pop('S15',None)\n",
    "length = []\n",
    "for x in interpDF:\n",
    "    length.append(len(interpDF[x]))\n",
    "index = min(length)\n",
    "print(index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date_Time</th>\n",
       "      <th>Dp&gt;0.3</th>\n",
       "      <th>Dp&gt;0.5</th>\n",
       "      <th>Dp&gt;1.0</th>\n",
       "      <th>Dp&gt;2.5</th>\n",
       "      <th>Dp&gt;5.0</th>\n",
       "      <th>Dp&gt;10.0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2021-04-20 09:32:30</td>\n",
       "      <td>60</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>2021-04-20 09:32:40</td>\n",
       "      <td>81</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>2021-04-20 09:32:50</td>\n",
       "      <td>39</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>2021-04-20 09:33:00</td>\n",
       "      <td>39</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Date_Time  Dp>0.3  Dp>0.5  Dp>1.0  Dp>2.5  Dp>5.0  Dp>10.0\n",
       "15 2021-04-20 09:32:30      60      13       0       0       0        0\n",
       "16 2021-04-20 09:32:40      81      20       0       0       0        0\n",
       "17 2021-04-20 09:32:50      39      13       0       0       0        0\n",
       "18 2021-04-20 09:33:00      39      10       0       0       0        0"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tempList = temp[15:19]\n",
    "tempList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 S-01\n",
      "2 S-02\n",
      "3 S-03\n",
      "4 S-04\n",
      "5 S-05\n",
      "6 S-06\n",
      "7 S-07\n",
      "8 S-08\n",
      "9 S-10\n",
      "10 S-12\n",
      "11 S-13\n",
      "12 S-14\n",
      "13 S-15\n",
      "14 S-16\n",
      "15 S-18\n",
      "16 S-19\n"
     ]
    }
   ],
   "source": [
    "for count,key in enumerate(list(interpDF.keys())):\n",
    "    print(count+1,key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'S-01':                Date_Time  Dp>0.3  Dp>0.5  Dp>1.0  Dp>2.5  Dp>5.0  Dp>10.0\n",
       " 0    2021-04-20 09:30:00      69      20       0       0       0        0\n",
       " 1    2021-04-20 09:30:10      48      13       0       0       0        0\n",
       " 2    2021-04-20 09:30:20      39      13       0       0       0        0\n",
       " 3    2021-04-20 09:30:30       9       3       0       0       0        0\n",
       " 4    2021-04-20 09:30:40      27       9       0       0       0        0\n",
       " ...                  ...     ...     ...     ...     ...     ...      ...\n",
       " 1531 2021-04-20 13:45:10       0       0       0       0       0        0\n",
       " 1532 2021-04-20 13:45:20       0       0       0       0       0        0\n",
       " 1533 2021-04-20 13:45:30       0       0       0       0       0        0\n",
       " 1534 2021-04-20 13:45:40       9       3       0       0       0        0\n",
       " 1535 2021-04-20 13:45:50       9       3       0       0       0        0\n",
       " \n",
       " [1536 rows x 7 columns],\n",
       " 'S-02':                Date_Time  Dp>0.3  Dp>0.5  Dp>1.0  Dp>2.5  Dp>5.0  Dp>10.0\n",
       " 0    2021-04-20 09:30:00      39      13       0       0       0        0\n",
       " 1    2021-04-20 09:30:10      93      24       7       0       0        0\n",
       " 2    2021-04-20 09:30:20      81      24       7       0       0        0\n",
       " 3    2021-04-20 09:30:30      48      12       0       0       0        0\n",
       " 4    2021-04-20 09:30:40      39       9       0       0       0        0\n",
       " ...                  ...     ...     ...     ...     ...     ...      ...\n",
       " 1532 2021-04-20 13:45:20       9       3       0       0       0        0\n",
       " 1533 2021-04-20 13:45:30       9       3       0       0       0        0\n",
       " 1534 2021-04-20 13:45:40       9       3       0       0       0        0\n",
       " 1535 2021-04-20 13:45:50       9       3       0       0       0        0\n",
       " 1536 2021-04-20 13:46:00       0       0       0       0       0        0\n",
       " \n",
       " [1537 rows x 7 columns],\n",
       " 'S-03':                Date_Time  Dp>0.3  Dp>0.5  Dp>1.0  Dp>2.5  Dp>5.0  Dp>10.0\n",
       " 0    2021-04-20 09:30:00      54      15       0       0       0        0\n",
       " 1    2021-04-20 09:30:10      54      18       0       0       0        0\n",
       " 2    2021-04-20 09:30:20      48       9       0       0       0        0\n",
       " 3    2021-04-20 09:30:30      69      16       0       0       0        0\n",
       " 4    2021-04-20 09:30:40      27       6       0       0       0        0\n",
       " ...                  ...     ...     ...     ...     ...     ...      ...\n",
       " 1527 2021-04-20 13:44:30      90      19       3       0       0        0\n",
       " 1528 2021-04-20 13:44:40      90      19       3       0       0        0\n",
       " 1529 2021-04-20 13:44:50       0       0       0       0       0        0\n",
       " 1530 2021-04-20 13:45:00       0       0       0       0       0        0\n",
       " 1531 2021-04-20 13:45:10       0       0       0       0       0        0\n",
       " \n",
       " [1532 rows x 7 columns],\n",
       " 'S-04':                Date_Time  Dp>0.3  Dp>0.5  Dp>1.0  Dp>2.5  Dp>5.0  Dp>10.0\n",
       " 0    2021-04-20 09:30:00      36       9       0       0       0        0\n",
       " 1    2021-04-20 09:30:10      84      28       0       0       0        0\n",
       " 2    2021-04-20 09:30:20      72      24       0       0       0        0\n",
       " 3    2021-04-20 09:30:30      39      13       0       0       0        0\n",
       " 4    2021-04-20 09:30:40      48      16       0       0       0        0\n",
       " ...                  ...     ...     ...     ...     ...     ...      ...\n",
       " 1550 2021-04-20 13:48:20       0       0       0       0       0        0\n",
       " 1551 2021-04-20 13:48:30       0       0       0       0       0        0\n",
       " 1552 2021-04-20 13:48:40       0       0       0       0       0        0\n",
       " 1553 2021-04-20 13:48:50       0       0       0       0       0        0\n",
       " 1554 2021-04-20 13:49:00       0       0       0       0       0        0\n",
       " \n",
       " [1555 rows x 7 columns],\n",
       " 'S-05':                Date_Time  Dp>0.3  Dp>0.5  Dp>1.0  Dp>2.5  Dp>5.0  Dp>10.0\n",
       " 0    2021-04-20 09:30:00      27       6       0       0       0        0\n",
       " 1    2021-04-20 09:30:10      18       3       0       0       0        0\n",
       " 2    2021-04-20 09:30:20      48      13       0       0       0        0\n",
       " 3    2021-04-20 09:30:30      48      13       0       0       0        0\n",
       " 4    2021-04-20 09:30:40      42      12       0       0       0        0\n",
       " ...                  ...     ...     ...     ...     ...     ...      ...\n",
       " 1519 2021-04-20 13:43:10      36      12       6       3       0        0\n",
       " 1520 2021-04-20 13:43:20       9       3       3       0       0        0\n",
       " 1521 2021-04-20 13:43:30       9       3       0       0       0        0\n",
       " 1522 2021-04-20 13:43:40      18       6       0       0       0        0\n",
       " 1523 2021-04-20 13:43:50       9       3       0       0       0        0\n",
       " \n",
       " [1524 rows x 7 columns],\n",
       " 'S-06':                Date_Time  Dp>0.3  Dp>0.5  Dp>1.0  Dp>2.5  Dp>5.0  Dp>10.0\n",
       " 0    2021-04-20 09:30:00      18       6       0       0       0        0\n",
       " 1    2021-04-20 09:30:10      81      23       3       3       3        3\n",
       " 2    2021-04-20 09:30:20      99      29       3       3       3        3\n",
       " 3    2021-04-20 09:30:30      36       9       0       0       0        0\n",
       " 4    2021-04-20 09:30:40      18       6       0       0       0        0\n",
       " ...                  ...     ...     ...     ...     ...     ...      ...\n",
       " 1520 2021-04-20 13:43:20       0       0       0       0       0        0\n",
       " 1521 2021-04-20 13:43:30       0       0       0       0       0        0\n",
       " 1522 2021-04-20 13:43:40       0       0       0       0       0        0\n",
       " 1523 2021-04-20 13:43:50       0       0       0       0       0        0\n",
       " 1524 2021-04-20 13:44:00       0       0       0       0       0        0\n",
       " \n",
       " [1525 rows x 7 columns],\n",
       " 'S-07':                Date_Time  Dp>0.3  Dp>0.5  Dp>1.0  Dp>2.5  Dp>5.0  Dp>10.0\n",
       " 0    2021-04-20 09:30:00     219      61       0       0       0        0\n",
       " 1    2021-04-20 09:30:10     147      46       0       0       0        0\n",
       " 2    2021-04-20 09:30:20      90      30       0       0       0        0\n",
       " 3    2021-04-20 09:30:30     126      33       0       0       0        0\n",
       " 4    2021-04-20 09:30:40      81      18       0       0       0        0\n",
       " ...                  ...     ...     ...     ...     ...     ...      ...\n",
       " 1528 2021-04-20 13:44:40       0       0       0       0       0        0\n",
       " 1529 2021-04-20 13:44:50       0       0       0       0       0        0\n",
       " 1530 2021-04-20 13:45:00       0       0       0       0       0        0\n",
       " 1531 2021-04-20 13:45:10       0       0       0       0       0        0\n",
       " 1532 2021-04-20 13:45:20       0       0       0       0       0        0\n",
       " \n",
       " [1533 rows x 7 columns],\n",
       " 'S-08':                Date_Time  Dp>0.3  Dp>0.5  Dp>1.0  Dp>2.5  Dp>5.0  Dp>10.0\n",
       " 0    2021-04-20 09:30:00     120      26       0       0       0        0\n",
       " 1    2021-04-20 09:30:10      81      20       0       0       0        0\n",
       " 2    2021-04-20 09:30:20      81      20       0       0       0        0\n",
       " 3    2021-04-20 09:30:30     205      40       0       0       0        0\n",
       " 4    2021-04-20 09:30:40     591     119       0       0       0        0\n",
       " ...                  ...     ...     ...     ...     ...     ...      ...\n",
       " 1538 2021-04-20 13:46:20       0       0       0       0       0        0\n",
       " 1539 2021-04-20 13:46:30       0       0       0       0       0        0\n",
       " 1540 2021-04-20 13:46:40       0       0       0       0       0        0\n",
       " 1541 2021-04-20 13:46:50       0       0       0       0       0        0\n",
       " 1542 2021-04-20 13:47:00       0       0       0       0       0        0\n",
       " \n",
       " [1543 rows x 7 columns],\n",
       " 'S-10':                Date_Time  Dp>0.3  Dp>0.5  Dp>1.0  Dp>2.5  Dp>5.0  Dp>10.0\n",
       " 0    2021-04-20 09:30:00      21       7       0       0       0        0\n",
       " 1    2021-04-20 09:30:10      66      22       0       0       0        0\n",
       " 2    2021-04-20 09:30:20      66      22       0       0       0        0\n",
       " 3    2021-04-20 09:30:30      69      21       0       0       0        0\n",
       " 4    2021-04-20 09:30:40      84      28       0       0       0        0\n",
       " ...                  ...     ...     ...     ...     ...     ...      ...\n",
       " 1522 2021-04-20 13:43:40       0       0       0       0       0        0\n",
       " 1523 2021-04-20 13:43:50       0       0       0       0       0        0\n",
       " 1524 2021-04-20 13:44:00      21       7       0       0       0        0\n",
       " 1525 2021-04-20 13:44:10      21       7       0       0       0        0\n",
       " 1526 2021-04-20 13:44:20      10       3       0       0       0        0\n",
       " \n",
       " [1527 rows x 7 columns],\n",
       " 'S-12':                Date_Time  Dp>0.3  Dp>0.5  Dp>1.0  Dp>2.5  Dp>5.0  Dp>10.0\n",
       " 0    2021-04-20 09:30:00      39      10       0       0       0        0\n",
       " 1    2021-04-20 09:30:10      39      10       0       0       0        0\n",
       " 2    2021-04-20 09:30:20      39      10       0       0       0        0\n",
       " 3    2021-04-20 09:30:30      72      20       0       0       0        0\n",
       " 4    2021-04-20 09:30:40     105      31       0       0       0        0\n",
       " ...                  ...     ...     ...     ...     ...     ...      ...\n",
       " 1527 2021-04-20 13:44:30       0       0       0       0       0        0\n",
       " 1528 2021-04-20 13:44:40       0       0       0       0       0        0\n",
       " 1529 2021-04-20 13:44:50      27       9       0       0       0        0\n",
       " 1530 2021-04-20 13:45:00      54      18       0       0       0        0\n",
       " 1531 2021-04-20 13:45:10      54      12       0       0       0        0\n",
       " \n",
       " [1532 rows x 7 columns],\n",
       " 'S-13':                Date_Time  Dp>0.3  Dp>0.5  Dp>1.0  Dp>2.5  Dp>5.0  Dp>10.0\n",
       " 0    2021-04-20 09:30:00      36      12       0       0       0        0\n",
       " 1    2021-04-20 09:30:10      72      24       0       0       0        0\n",
       " 2    2021-04-20 09:30:20      36      12       0       0       0        0\n",
       " 3    2021-04-20 09:30:30      75      25       0       0       0        0\n",
       " 4    2021-04-20 09:30:40      75      25       0       0       0        0\n",
       " ...                  ...     ...     ...     ...     ...     ...      ...\n",
       " 1523 2021-04-20 13:43:50      18       6       3       3       3        1\n",
       " 1524 2021-04-20 13:44:00       9       3       0       0       0        0\n",
       " 1525 2021-04-20 13:44:10       0       0       0       0       0        0\n",
       " 1526 2021-04-20 13:44:20       0       0       0       0       0        0\n",
       " 1527 2021-04-20 13:44:30       0       0       0       0       0        0\n",
       " \n",
       " [1528 rows x 7 columns],\n",
       " 'S-14':                Date_Time  Dp>0.3  Dp>0.5  Dp>1.0  Dp>2.5  Dp>5.0  Dp>10.0\n",
       " 0    2021-04-20 09:30:00      63      21       0       0       0        0\n",
       " 1    2021-04-20 09:30:10      63      21       0       0       0        0\n",
       " 2    2021-04-20 09:30:20      45      15       0       0       0        0\n",
       " 3    2021-04-20 09:30:30      54      18       3       0       0        0\n",
       " 4    2021-04-20 09:30:40      54      18       3       0       0        0\n",
       " ...                  ...     ...     ...     ...     ...     ...      ...\n",
       " 1519 2021-04-20 13:43:10       0       0       0       0       0        0\n",
       " 1520 2021-04-20 13:43:20       4       1       0       0       0        0\n",
       " 1521 2021-04-20 13:43:30       0       0       0       0       0        0\n",
       " 1522 2021-04-20 13:43:40       0       0       0       0       0        0\n",
       " 1523 2021-04-20 13:43:50       0       0       0       0       0        0\n",
       " \n",
       " [1524 rows x 7 columns],\n",
       " 'S-15':                Date_Time  Dp>0.3  Dp>0.5  Dp>1.0  Dp>2.5  Dp>5.0  Dp>10.0\n",
       " 0    2021-04-20 09:30:00      33      11       0       0       0        0\n",
       " 1    2021-04-20 09:30:10      75      25       0       0       0        0\n",
       " 2    2021-04-20 09:30:20      54      18       0       0       0        0\n",
       " 3    2021-04-20 09:30:30      21       7       0       0       0        0\n",
       " 4    2021-04-20 09:30:40      39      10       0       0       0        0\n",
       " ...                  ...     ...     ...     ...     ...     ...      ...\n",
       " 1548 2021-04-20 13:48:00       0       0       0       0       0        0\n",
       " 1549 2021-04-20 13:48:10       0       0       0       0       0        0\n",
       " 1550 2021-04-20 13:48:20       0       0       0       0       0        0\n",
       " 1551 2021-04-20 13:48:30       9       3       0       0       0        0\n",
       " 1552 2021-04-20 13:48:40       9       3       0       0       0        0\n",
       " \n",
       " [1553 rows x 7 columns],\n",
       " 'S-16':                Date_Time  Dp>0.3  Dp>0.5  Dp>1.0  Dp>2.5  Dp>5.0  Dp>10.0\n",
       " 0    2021-04-20 09:30:00       0       0       0       0       0        0\n",
       " 1    2021-04-20 09:30:10       0       0       0       0       0        0\n",
       " 2    2021-04-20 09:30:20       0       0       0       0       0        0\n",
       " 3    2021-04-20 09:30:30       0       0       0       0       0        0\n",
       " 4    2021-04-20 09:30:40       0       0       0       0       0        0\n",
       " ...                  ...     ...     ...     ...     ...     ...      ...\n",
       " 1551 2021-04-20 13:48:30       9       3       0       0       0        0\n",
       " 1552 2021-04-20 13:48:40       9       3       0       0       0        0\n",
       " 1553 2021-04-20 13:48:50       0       0       0       0       0        0\n",
       " 1554 2021-04-20 13:49:00       0       0       0       0       0        0\n",
       " 1555 2021-04-20 13:49:10       0       0       0       0       0        0\n",
       " \n",
       " [1556 rows x 7 columns],\n",
       " 'S-18':                Date_Time  Dp>0.3  Dp>0.5  Dp>1.0  Dp>2.5  Dp>5.0  Dp>10.0\n",
       " 0    2021-04-20 09:30:00      42       7       0       0       0        0\n",
       " 1    2021-04-20 09:30:10      30       7       0       0       0        0\n",
       " 2    2021-04-20 09:30:20      57      19       0       0       0        0\n",
       " 3    2021-04-20 09:30:30      36      12       0       0       0        0\n",
       " 4    2021-04-20 09:30:40      30      10       0       0       0        0\n",
       " ...                  ...     ...     ...     ...     ...     ...      ...\n",
       " 1547 2021-04-20 13:47:50       0       0       0       0       0        0\n",
       " 1548 2021-04-20 13:48:00       0       0       0       0       0        0\n",
       " 1549 2021-04-20 13:48:10       0       0       0       0       0        0\n",
       " 1550 2021-04-20 13:48:20       0       0       0       0       0        0\n",
       " 1551 2021-04-20 13:48:30       0       0       0       0       0        0\n",
       " \n",
       " [1552 rows x 7 columns],\n",
       " 'S-19':                Date_Time  Dp>0.3  Dp>0.5  Dp>1.0  Dp>2.5  Dp>5.0  Dp>10.0\n",
       " 0    2021-04-20 09:30:00      27       9       0       0       0        0\n",
       " 1    2021-04-20 09:30:10      27       9       0       0       0        0\n",
       " 2    2021-04-20 09:30:20      57      19       0       0       0        0\n",
       " 3    2021-04-20 09:30:30      57      19       0       0       0        0\n",
       " 4    2021-04-20 09:30:40      27       9       0       0       0        0\n",
       " ...                  ...     ...     ...     ...     ...     ...      ...\n",
       " 1551 2021-04-20 13:48:30       0       0       0       0       0        0\n",
       " 1552 2021-04-20 13:48:40       0       0       0       0       0        0\n",
       " 1553 2021-04-20 13:48:50       0       0       0       0       0        0\n",
       " 1554 2021-04-20 13:49:00       0       0       0       0       0        0\n",
       " 1555 2021-04-20 13:49:10       9       3       0       0       0        0\n",
       " \n",
       " [1556 rows x 7 columns]}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "interpDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfMerged = []\n",
    "columns = list(interpDF.keys())\n",
    "columns.extend(['Average',\n",
    "'Variance',\n",
    "'Zone 1',\n",
    "'Var Z1',\n",
    "'Zone 2',\n",
    "'Var Z2',\n",
    "'Zone 3',\n",
    "'Var Z3'])\n",
    "# 'Zone 4',\n",
    "# 'Var Z4'])\n",
    "\n",
    "for idx,i in enumerate(interpDF[columns[0]].values[:index]):\n",
    "    temp = []\n",
    "    temp.append(i[0])\n",
    "    for x in interpDF:\n",
    "        temp.append(interpDF[x].values[idx][1])\n",
    "    #So we now have a list with the timestamp and then sensors\n",
    "    \n",
    "    #here we add the overall average and variance columns\n",
    "    temp.append(np.average(temp[1:16]))\n",
    "    temp.append(np.std(temp[1:16]))\n",
    "\n",
    "    #here we're segregating the zones in the file giving their variance and avg\n",
    "\n",
    "    #Zone 1 the 2 sensors right on top of the nebulizer\n",
    "    lst = temp[1:7]\n",
    "    temp.append(np.average(lst))\n",
    "    temp.append(np.std(lst))\n",
    "    # #Zone 2 the perimeter of the bed\n",
    "    # lst = [temp[2],temp[3],temp[5],temp[6]]\n",
    "    # temp.append(np.average(lst))\n",
    "    # temp.append(np.std(lst))\n",
    "    #Zone 3 the perimeter of the room\n",
    "    lst = temp[7:16]\n",
    "    temp.append(np.average(lst))\n",
    "    temp.append(np.std(lst))\n",
    "    #Zone 4 is just the outside sensor\n",
    "    lst = temp[16:19]\n",
    "    temp.append(np.average(lst))\n",
    "    temp.append(np.std(lst))\n",
    "    dfMerged.append(temp)\n",
    "columns.insert(0,'Date_Time')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['S-01', 'S-02', 'S-03', 'S-04', 'S-05', 'S-06', 'S-07', 'S-08', 'S-10', 'S-12', 'S-13', 'S-14', 'S-15', 'S-16', 'S-18', 'S-19'])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "interpDF.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "mergedData = pd.DataFrame(dfMerged,columns = columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date_Time</th>\n",
       "      <th>S-01</th>\n",
       "      <th>S-02</th>\n",
       "      <th>S-03</th>\n",
       "      <th>S-04</th>\n",
       "      <th>S-05</th>\n",
       "      <th>S-06</th>\n",
       "      <th>S-07</th>\n",
       "      <th>S-08</th>\n",
       "      <th>S-10</th>\n",
       "      <th>...</th>\n",
       "      <th>S-18</th>\n",
       "      <th>S-19</th>\n",
       "      <th>Average</th>\n",
       "      <th>Variance</th>\n",
       "      <th>Zone 1</th>\n",
       "      <th>Var Z1</th>\n",
       "      <th>Zone 2</th>\n",
       "      <th>Var Z2</th>\n",
       "      <th>Zone 3</th>\n",
       "      <th>Var Z3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2021-04-20 09:30:00</td>\n",
       "      <td>69</td>\n",
       "      <td>39</td>\n",
       "      <td>54</td>\n",
       "      <td>36</td>\n",
       "      <td>27</td>\n",
       "      <td>18</td>\n",
       "      <td>219</td>\n",
       "      <td>120</td>\n",
       "      <td>21</td>\n",
       "      <td>...</td>\n",
       "      <td>42</td>\n",
       "      <td>27</td>\n",
       "      <td>54.400000</td>\n",
       "      <td>51.379373</td>\n",
       "      <td>40.5</td>\n",
       "      <td>16.859715</td>\n",
       "      <td>63.666667</td>\n",
       "      <td>63.210407</td>\n",
       "      <td>44.259791</td>\n",
       "      <td>12.266658</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2021-04-20 09:30:10</td>\n",
       "      <td>48</td>\n",
       "      <td>93</td>\n",
       "      <td>54</td>\n",
       "      <td>84</td>\n",
       "      <td>18</td>\n",
       "      <td>81</td>\n",
       "      <td>147</td>\n",
       "      <td>81</td>\n",
       "      <td>66</td>\n",
       "      <td>...</td>\n",
       "      <td>30</td>\n",
       "      <td>27</td>\n",
       "      <td>63.400000</td>\n",
       "      <td>33.903392</td>\n",
       "      <td>63.0</td>\n",
       "      <td>25.806976</td>\n",
       "      <td>63.666667</td>\n",
       "      <td>38.360860</td>\n",
       "      <td>41.434464</td>\n",
       "      <td>15.785601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2021-04-20 09:30:20</td>\n",
       "      <td>39</td>\n",
       "      <td>81</td>\n",
       "      <td>48</td>\n",
       "      <td>72</td>\n",
       "      <td>48</td>\n",
       "      <td>99</td>\n",
       "      <td>90</td>\n",
       "      <td>81</td>\n",
       "      <td>66</td>\n",
       "      <td>...</td>\n",
       "      <td>57</td>\n",
       "      <td>57</td>\n",
       "      <td>57.000000</td>\n",
       "      <td>24.445859</td>\n",
       "      <td>64.5</td>\n",
       "      <td>21.266170</td>\n",
       "      <td>52.000000</td>\n",
       "      <td>25.139610</td>\n",
       "      <td>46.148620</td>\n",
       "      <td>15.346169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2021-04-20 09:30:30</td>\n",
       "      <td>9</td>\n",
       "      <td>48</td>\n",
       "      <td>69</td>\n",
       "      <td>39</td>\n",
       "      <td>48</td>\n",
       "      <td>36</td>\n",
       "      <td>126</td>\n",
       "      <td>205</td>\n",
       "      <td>69</td>\n",
       "      <td>...</td>\n",
       "      <td>36</td>\n",
       "      <td>57</td>\n",
       "      <td>60.466667</td>\n",
       "      <td>48.681094</td>\n",
       "      <td>41.5</td>\n",
       "      <td>17.951323</td>\n",
       "      <td>73.111111</td>\n",
       "      <td>57.751276</td>\n",
       "      <td>55.382587</td>\n",
       "      <td>4.945500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2021-04-20 09:30:40</td>\n",
       "      <td>27</td>\n",
       "      <td>39</td>\n",
       "      <td>27</td>\n",
       "      <td>48</td>\n",
       "      <td>42</td>\n",
       "      <td>18</td>\n",
       "      <td>81</td>\n",
       "      <td>591</td>\n",
       "      <td>84</td>\n",
       "      <td>...</td>\n",
       "      <td>30</td>\n",
       "      <td>27</td>\n",
       "      <td>84.000000</td>\n",
       "      <td>138.182488</td>\n",
       "      <td>33.5</td>\n",
       "      <td>10.307764</td>\n",
       "      <td>117.666667</td>\n",
       "      <td>170.057507</td>\n",
       "      <td>83.060829</td>\n",
       "      <td>45.394919</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1519</th>\n",
       "      <td>2021-04-20 13:43:10</td>\n",
       "      <td>21</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>36</td>\n",
       "      <td>0</td>\n",
       "      <td>18</td>\n",
       "      <td>9</td>\n",
       "      <td>57</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>12.666667</td>\n",
       "      <td>15.421486</td>\n",
       "      <td>12.5</td>\n",
       "      <td>12.658989</td>\n",
       "      <td>12.777778</td>\n",
       "      <td>17.014881</td>\n",
       "      <td>9.362717</td>\n",
       "      <td>6.715287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1520</th>\n",
       "      <td>2021-04-20 13:43:20</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>28</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6.333333</td>\n",
       "      <td>7.862711</td>\n",
       "      <td>4.5</td>\n",
       "      <td>4.500000</td>\n",
       "      <td>7.555556</td>\n",
       "      <td>9.262962</td>\n",
       "      <td>4.732015</td>\n",
       "      <td>3.403794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1521</th>\n",
       "      <td>2021-04-20 13:43:30</td>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>21</td>\n",
       "      <td>2.666667</td>\n",
       "      <td>5.133766</td>\n",
       "      <td>4.5</td>\n",
       "      <td>6.873864</td>\n",
       "      <td>1.444444</td>\n",
       "      <td>2.948111</td>\n",
       "      <td>9.600144</td>\n",
       "      <td>8.123594</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1522</th>\n",
       "      <td>2021-04-20 13:43:40</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>126</td>\n",
       "      <td>30</td>\n",
       "      <td>13.800000</td>\n",
       "      <td>30.629398</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.708204</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>38.288379</td>\n",
       "      <td>24.809799</td>\n",
       "      <td>7.789343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1523</th>\n",
       "      <td>2021-04-20 13:43:50</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>126</td>\n",
       "      <td>9</td>\n",
       "      <td>13.800000</td>\n",
       "      <td>30.452586</td>\n",
       "      <td>4.5</td>\n",
       "      <td>4.500000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>37.894591</td>\n",
       "      <td>17.750862</td>\n",
       "      <td>9.192763</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1524 rows Ã— 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               Date_Time  S-01  S-02  S-03  S-04  S-05  S-06  S-07  S-08  \\\n",
       "0    2021-04-20 09:30:00    69    39    54    36    27    18   219   120   \n",
       "1    2021-04-20 09:30:10    48    93    54    84    18    81   147    81   \n",
       "2    2021-04-20 09:30:20    39    81    48    72    48    99    90    81   \n",
       "3    2021-04-20 09:30:30     9    48    69    39    48    36   126   205   \n",
       "4    2021-04-20 09:30:40    27    39    27    48    42    18    81   591   \n",
       "...                  ...   ...   ...   ...   ...   ...   ...   ...   ...   \n",
       "1519 2021-04-20 13:43:10    21     9     9     0    36     0    18     9   \n",
       "1520 2021-04-20 13:43:20     9     9     0     0     9     0     9     0   \n",
       "1521 2021-04-20 13:43:30    18     0     0     0     9     0     0     0   \n",
       "1522 2021-04-20 13:43:40     9     0     9     0    18     0     9     0   \n",
       "1523 2021-04-20 13:43:50     9     0     9     0     9     0     9     9   \n",
       "\n",
       "      S-10  ...  S-18  S-19    Average    Variance  Zone 1     Var Z1  \\\n",
       "0       21  ...    42    27  54.400000   51.379373    40.5  16.859715   \n",
       "1       66  ...    30    27  63.400000   33.903392    63.0  25.806976   \n",
       "2       66  ...    57    57  57.000000   24.445859    64.5  21.266170   \n",
       "3       69  ...    36    57  60.466667   48.681094    41.5  17.951323   \n",
       "4       84  ...    30    27  84.000000  138.182488    33.5  10.307764   \n",
       "...    ...  ...   ...   ...        ...         ...     ...        ...   \n",
       "1519    57  ...     0     0  12.666667   15.421486    12.5  12.658989   \n",
       "1520    28  ...     0     0   6.333333    7.862711     4.5   4.500000   \n",
       "1521     0  ...     0    21   2.666667    5.133766     4.5   6.873864   \n",
       "1522     0  ...   126    30  13.800000   30.629398     6.0   6.708204   \n",
       "1523     0  ...   126     9  13.800000   30.452586     4.5   4.500000   \n",
       "\n",
       "          Zone 2      Var Z2     Zone 3     Var Z3  \n",
       "0      63.666667   63.210407  44.259791  12.266658  \n",
       "1      63.666667   38.360860  41.434464  15.785601  \n",
       "2      52.000000   25.139610  46.148620  15.346169  \n",
       "3      73.111111   57.751276  55.382587   4.945500  \n",
       "4     117.666667  170.057507  83.060829  45.394919  \n",
       "...          ...         ...        ...        ...  \n",
       "1519   12.777778   17.014881   9.362717   6.715287  \n",
       "1520    7.555556    9.262962   4.732015   3.403794  \n",
       "1521    1.444444    2.948111   9.600144   8.123594  \n",
       "1522   19.000000   38.288379  24.809799   7.789343  \n",
       "1523   20.000000   37.894591  17.750862   9.192763  \n",
       "\n",
       "[1524 rows x 25 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mergedData"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Increase Resolution on Merged Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in mergedData:\n",
    "    tempFrame = mergedData.values\n",
    "    tempList = []\n",
    "    for idx,x in enumerate(tempFrame):\n",
    "        try:\n",
    "            increment = (tempFrame[idx+1] - x)/10\n",
    "            for count in range(10):\n",
    "                tempList.append(x+increment*count)\n",
    "        except IndexError:\n",
    "            tempList.append(x)\n",
    "            continue\n",
    "    hiResMergedDF = pd.DataFrame(tempList, columns = mergedData.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export Merged Frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "directory = './mergedData/'\n",
    "if not os.path.exists(directory):\n",
    "\n",
    "    os.makedirs(directory)\n",
    "\n",
    "location = os.path.join(directory+'mergedFrame.csv')\n",
    "hiResMergedDF.to_csv(location,index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create csv File for each Animation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have 3 expirements in each that we want to average across the range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "expTRange = {\n",
    "\n",
    "    'ICU Room 1 Door Partially Open':\n",
    "    [pd.Timestamp('2021-04-20 9:45:15'),\n",
    "    pd.Timestamp('2021-04-20 10:02:40'),\n",
    "    pd.Timestamp('2021-04-20 10:19:40')],\n",
    "    'ICU Room 1 Door Open':\n",
    "    [pd.Timestamp('2021-04-20 10:35:05'),\n",
    "    pd.Timestamp('2021-04-20 10:51:15'),\n",
    "    pd.Timestamp('2021-04-20 11:06:30')],\n",
    "    'ICU Room 1 Negative Pressure':\n",
    "    [pd.Timestamp('2021-04-20 11:25:00'),\n",
    "    pd.Timestamp('2021-04-20 11:37:50'),\n",
    "    pd.Timestamp('2021-04-20 11:47:55')],\n",
    "    'ICU Room 2 Door Partially Open':\n",
    "    [pd.Timestamp('2021-04-20 12:13:35'),\n",
    "    pd.Timestamp('2021-04-20 12:23:30'),\n",
    "    pd.Timestamp('2021-04-20 12:38:30'),\n",
    "    pd.Timestamp('2021-04-20 12:49:45')],\n",
    "    'ICU Room 2 Door Open':\n",
    "    [pd.Timestamp('2021-04-20 13:00:30'),\n",
    "    pd.Timestamp('2021-04-20 13:13:30'),\n",
    "    pd.Timestamp('2021-04-20 13:23:30'),\n",
    "    pd.Timestamp('2021-04-20 13:33:00')],\n",
    "}\n",
    "\n",
    "#enter in the expirement length as seconds/10\n",
    "expTLen = {\n",
    "    'ICU Room 1 Door Partially Open' : 15*6,\n",
    "    'ICU Room 1 Door Open':15*6,\n",
    "    'ICU Room 1 Negative Pressure':10*6,\n",
    "    'ICU Room 2 Door Partially Open':15*6,\n",
    "    'ICU Room 2 Door Open':10*6   \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#mergedData = pd.read_csv('./mergedData/mergedFrame.csv',parse_dates=[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "time = mergedData['Date_Time']\n",
    "expIndexes = {}\n",
    "for i in expTRange:\n",
    "    expIndexes[i] = []\n",
    "    for x in expTRange[i]:\n",
    "        for start,n in enumerate(time):\n",
    "           if n >= x:\n",
    "               expIndexes[i].append(start)\n",
    "               break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\kaitl\\\\Desktop\\\\HospitalAerosolTesting\\\\Data\\\\UWMedApril20'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      2021-04-20 09:30:00\n",
       "1      2021-04-20 09:30:10\n",
       "2      2021-04-20 09:30:20\n",
       "3      2021-04-20 09:30:30\n",
       "4      2021-04-20 09:30:40\n",
       "               ...        \n",
       "1519   2021-04-20 13:43:10\n",
       "1520   2021-04-20 13:43:20\n",
       "1521   2021-04-20 13:43:30\n",
       "1522   2021-04-20 13:43:40\n",
       "1523   2021-04-20 13:43:50\n",
       "Name: Date_Time, Length: 1524, dtype: datetime64[ns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ICU Room 1 Door Partially Open': [92, 196, 298],\n",
       " 'ICU Room 1 Door Open': [391, 488, 579],\n",
       " 'ICU Room 1 Negative Pressure': [690, 767, 828],\n",
       " 'ICU Room 2 Door Partially Open': [982, 1041, 1131, 1199],\n",
       " 'ICU Room 2 Door Open': [1263, 1341, 1401, 1458]}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "expIndexes#expTLen[label]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# controls how many seconds of data before each experiment to include\n",
    "preCursorFactor = 0\n",
    "averagedFrame = {}\n",
    "expirementFrame = {}\n",
    "\n",
    "for label in expIndexes:\n",
    "\n",
    "    df1Index1 = expIndexes[label][0] - preCursorFactor\n",
    "    df1Index2 = expIndexes[label][0] + expTLen[label]\n",
    "    df1 = mergedData.iloc[df1Index1 : df1Index2 , 1: ].reset_index(drop = True)\n",
    "\n",
    "    df2Index1 = expIndexes[label][1] - preCursorFactor\n",
    "    df2Index2 = expIndexes[label][1] + expTLen[label]\n",
    "    df2 = mergedData.iloc[df2Index1 : df2Index2 , 1: ].reset_index(drop = True)\n",
    "\n",
    "    df3Index1 = expIndexes[label][2] - preCursorFactor\n",
    "    df3Index2 = expIndexes[label][2] + expTLen[label]\n",
    "    df3 = mergedData.iloc[df3Index1 : df3Index2 , 1: ].reset_index(drop = True)\n",
    "\n",
    "    averagedFrame[label] = (df1 + df2 + df3)/3\n",
    "\n",
    "    expirementFrame[label+' Exp1'] = df1\n",
    "    expirementFrame[label+' Exp2'] = df2\n",
    "    expirementFrame[label+' Exp3'] = df3\n",
    "    \n",
    "#assuming there were 3 expirements for each one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "directory = './averagedData'\n",
    "if not os.path.exists(directory):\n",
    "    os.makedirs(directory)\n",
    "for x in averagedFrame:\n",
    "    temp=averagedFrame[x]\n",
    "    location = os.path.join(directory,x+'.csv')\n",
    "    temp.to_csv(location,index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "directory = './expirementData'\n",
    "if not os.path.exists(directory):\n",
    "    os.makedirs(directory)\n",
    "for x in expirementFrame:\n",
    "    temp=expirementFrame[x]\n",
    "    location = os.path.join(directory,x+'.csv')\n",
    "    temp.to_csv(location,index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Increase the Resolution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "pad out the dataframes to have values for every second."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "stretchedDF = {}\n",
    "for i in averagedFrame:\n",
    "    tempFrame = averagedFrame[i].values\n",
    "    tempList = []\n",
    "    for idx,x in enumerate(tempFrame):\n",
    "        try:\n",
    "            increment = (tempFrame[idx+1] - x)/10\n",
    "            for count in range(10):\n",
    "                tempList.append(x+increment*count)\n",
    "        except IndexError:\n",
    "            tempList.append(x)\n",
    "            continue\n",
    "    stretchedDF[i] = pd.DataFrame(tempList, columns = expirementFrame[list(expirementFrame.keys())[0]].columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "stretchExpDf = {}\n",
    "for i in expirementFrame:\n",
    "    tempFrame = expirementFrame[i].values\n",
    "    tempList = []\n",
    "    for idx,x in enumerate(tempFrame):\n",
    "        try:\n",
    "            increment = (tempFrame[idx+1] - x)/10\n",
    "            for count in range(10):\n",
    "                tempList.append(x+increment*count)\n",
    "        except IndexError:\n",
    "            tempList.append(x)\n",
    "            continue\n",
    "    stretchExpDf[i] = pd.DataFrame(tempList, columns = expirementFrame[list(expirementFrame.keys())[0]].columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(directory):\n",
    "    os.makedirs(directory)\n",
    "for x in stretchedDF:\n",
    "    temp=stretchedDF[x]\n",
    "    location = os.path.join(directory,x+'.csv')\n",
    "    temp.to_csv(location,index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "directory = './stretchedExpirementData'\n",
    "if not os.path.exists(directory):\n",
    "    os.makedirs(directory)\n",
    "for x in stretchExpDf:\n",
    "    temp=stretchExpDf[x]\n",
    "    location = os.path.join(directory,x+'.csv')\n",
    "    temp.to_csv(location,index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
